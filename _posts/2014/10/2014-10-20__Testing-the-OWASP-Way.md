---
layout: default
author: Chris Cornutt
email: ccornutt@phpdeveloper.org
title: Testing the OWASP Way - Introduction
tags: shellshock,php,bash,vulnerability
summary:
---

Testing the OWASP Way - Introduction
--------------

{{ byline }}

The [Open Web Application Security Project](http://owasp.org) (or OWASP as it's more commonly referred to) recently announced the release of the latest version of their testing guide, version four. [The guide](https://www.owasp.org/images/5/52/OWASP_Testing_Guide_v4.pdf) provides a comprehensive listing of tests you can perform against your web-based applications to ensure they're hardened against attacks.

@todo
threat modeling
also comments about integrating security testing into your workflow
talks about reporting on security issues for visibility

### Categories

They've broken the guide up into eleven different categories to make consuming it a bit easier. Here's the thousand-foot view of the topics and a brief look at what each entails:

##### I. Information Gathering

This kind of testing could almost be thought of more as general reconnaissance. The whole goal of this group is to gather some of the "metadata" around the application you're targeting and information you can glean from other outside sources. This includes the results found in popular search engines and the overall architecture of the application.

The idea of "fingerprinting" is brought up in this category. This is essentially what it sounds like: using various attributes of the application to create a unique value (hash or otherwise) to identify it. This fingerprint can include the content from a number of different attributes, but they suggest three to get you started: identifying the web server software, figuring out the application framework in use and any application that might be sitting on top of it.

Having these fingerprints can also help you detect when an application changes. Depending on how you create the fingerprint, you might even be able to tell when anything in the application's environment changes, even down to the host that it lives on. It also provides a unique identifier you can use to track the application in your systems and its change over time. All applications change in both subtle and not so subtle ways and tracking this can help aid your testing and make it simpler to know when tests and policies need to be revised.

For example, if we were to profile a simple PHP application, we might be able to determine it's running on an Apache web server based on headers returned from a simple HTTP `GET` request. Taking the next step "up" we can look at the framework that the application is being run on. In the PHP world, this might be something like [Zend Framework](http://framework.zend.com) or [Symfony](http://symfony.com). If it's a custom application running one of these frameworks, it might be difficult to determine which it is, but there can be some tell-tale signs, especially if they're using a default setup.

Since PHP has been around for a long time, there's no shortage of applications out there. Changes are, if it's not a custom application, you can figure out what kind of software is running a site just from the look and feel or even a glance at the page source. Don't forget about other data surrounding applications too...even things like cookie names can shed some light on your research.

Other information they suggest including in your discovery includes details that could be gleaned from web server configuration files (think `robots.txt`), the workflow through the application, other applications that might be living on the same server and information from cached error or exception messages a service might have stored.

##### II. Configuration & Deployment Management

Next up is a quick set of recommendations around testing of the configuration and deployment of the application and the platform it lives on. Web-based applications can't exist in isolation. They have to run on some kind of server and network to even be accessible to users. This set of tests help you track down some of these other environmental issues that could lead to potential compromises in your applications.

First they recommend testing the configuration of the platform the application lives on and validate that there's not extra or default settings enabled that could leave a hole for an attacker to abuse. Most web servers will come with a default configuration defined to make the setup process a bit less painful. Unfortunately this can also be detrimental to the platform and application, especially for administrators that may not know any better. The general rule here is: "if you don't know what it does or if you need it, turn it off."

There's also another kind of discovery that can be done with a little bit of digging and knowing where to look. Developers and site administrators are creatures of habit and one unfortunate habit several have picked up over the years is to leave copies of older configurations, files not referenced anywhere and backup copies where they're web accessible. Remember, just because there's not something in your application that points to a script it means it's secure. This is the very definition of "security through obscurity" and trust me...that never ends well.

The end of this section includes a few other exploratory suggestions to help you determine the "edges" of the application. The first recommendation is to test other HTTP methods besides the ones used in the site. I've seen some PHP applications that split out the `POST` handling from the `GET` in the same controller (REST anyone?) but don't think about securing the `POST` route since nothing in the application submits to it. The unfortunate reality is that, even if the site only uses a request like `GET /foo/bar` an attacker could see this and start messing with `POST`, `PUT` or even `DELETE` and see how the application behaves.

The last two deal with checking for the the strict transport security header (`Strict-Transport-Security`) and the potential use of RIA (rich internet application) cross-domain policies. Cross-domain policies can grant or deny several different kinds of low-level handling including socket permissioning, header handling and the requirements for HTTP/HTTPS.

##### III. Identity Management

This next section includes a few test that center around the identity of your users and some of the common methods of handling them. Every application is going to handle their user authentication and authorization differently (there's just so many possible options out there) but there are a few things that are common to web applications at a higher level. The first of these is the concept of *roles*. Most simple applications will have at least two user role concepts: a normal user that can do things related to their account and an administrator that can work with features in the system that cross user accounts or manage the application itself. While there are some tactics for determining these things as an outsider, one of the more efficient things they recommend, as someone who knows the application inside and out, is to create a *permission matrix"

In this matrix you outline the type of role the user has (ex user vs administrator), what the permission is, why the would need to have it (the objective) and any constraints that may need to be put on it. Simple permission logic - has or doesn't have - is pretty easy but when you start entering the world of [role-based access control](http://en.wikipedia.org/wiki/Role-based_access_control) things start getting complex pretty quickly. You start having to have conversations like "If User #1 has the 'view all' permission, do we want to limit them from seeing Administrator accounts in that list" or "Should an Administrator be able to change information about a locked user?". All of these decisions relate to more complex permissions and groupings. By laying out the possible options in a matrix like this, you can see patterns and wrap your head around what objectives need to be done rather than doling out one-off permissions each time there's a variance.

Next up is something that's a bit more user facing: testing of the registration form. Just about any application that has users has some kind of registration option. Sure, there's some that just authenticate off of another source, but probably ninety percent of the time users and permissions will be an internal thing. This testing isn't so much about things like SQL injection or the allowance of XSS, though. It's more about ensuring that there's no extra information exposure on the messaging or that the rules enforced match what's expected by the business. You can have even more complexity here if users are able to request permissions to access other parts of the application. Then you have to rely more heavily on that matrix to ensure that there's no unfortunate side effects by granting one permission and having it cascading down and possibly negating out another one.

Following the registration process is a look at the next step in the chain: ensuring that the actual process for creating the user is working as expected and that all required information is obtained. Some of this was taken care of in the previous step, but consider this aspect of it as well - can your application administrators create users too, outside of the normal registration process? If so, are they still required to fill in all of the required information any other user would have to submit? Remember, just because their administrators it doesn't mean they should get to work around common things like business rules and validation. Those things are fundamental to the application working correctly and the data it houses always being valid.

In the next recommended test, the OWASP guide suggests avoiding situations where usernames could be guessable. This is pretty obvious when you think about it, but it's easy to forget when you're neck deep in the code. There's really two pieces to this kind of testing. The first is not making automatically generated usernames guessable. Some services will create a username for you as a part of the registration process or they might reuse another piece of data like your full name or email address. In this case, it's relatively easy to guess what a person's username might be. It's pretty common to see the first letter + last name combination, especially in business environment. This is usually set up to help keep standards across an organization but it also makes the username *very* easy to guess. The same kind of thing goes for email addresses. Remember, email addresses are public knowledge and should be treated as such. You're better off allowing the users to select their own usernames than trying to generate your own. Sure, it's a little bit harder to track the actual person down that's done bad things to your system, but it's better than the potential compromise of a large swath of accounts.

The second point around the username enumeration is ensuring that things like password reset functionality or even the login process don't give away the existence of an account in the system. There's been several articles written up about the messaging that users receive from bad logins or resets that expose too much information, things like: "That user doesn't exist in our system" or "This user is inactive and cannot log in". Either of these messages can give a potential attacker additional information they might need. The first lets them know that the given username doesn't exist so they can cross those off their list. On the flip side, if they *don't* get this message, they know the account is valid and they can continue on their merry way. The second message talks more about the state of the user. This lets an attacker know that there are both active and inactive accounts in the system and what they are. They can also assume that there's a way somewhere for administrators to re-enable the user, enticing them even more to find and brute force their way into an admin account.

Remember not to just think about web applications here - APIs are also vulnerable to the same kind of issues and potential leakage via error messaging. If you make a request to a `/user/login` endpoint and are quickly returned with an error code in the `400` range of HTTP responses (and the API is correctly RESTish) you'll know more about the user in question. If you get a `403 Forbiddenn` you know the user exists but you're not allowed to access that resource. If you get a `404 Not Found` chances are the user isn't in the system and you should keep trying.

Be sure the messaging you're providing is informative enough to provide meaning to the user but also generic enough to not leak any kind of data that could be used against you. Some examples of potential messages might be:

- "The credentials provided we not valid."
- "If the matching account is found, an email will be sent with password reset instructions."
- "There is a problem with your credentials, please contact an administrator for assistance."

You also need to be sure that whatever policies your application enforces on the user-facing side (like the registration form) is used everywhere in the system. Any time you're working with usernames, be sure you're running validation on it, even better if it's run even when a user is viewed or otherwise output.

##### IV. Authentication

Now we get into something a bit more complex - authentication. The previous section shared some testing advice for the general identity management handling of the application. Things like username enumeration or using a role matrix fit with just about any application out there. When you start to look at how it performs authorization, you start getting more into the "guts" of the system. It becomes more about *how* things are implemented and not just *what* is implemented.

There's a few of the points in this section that deal with weaknesses common to authentication handling, the first of which is sending sensitive information - in this case credentials - over an open or unencrypted channel. Think about an application that's largely driven by Javascript. This application has to communicate with an API backend to get information to share with the user. Obviously we want a way to identify the user that's making the request so we have them log into the system. The backend now knows who they are, but what about the frontend? I've seen some applications that take some kind of identifier, either something derived from the username/password or some kind of token and use that in their requests back and forth with the server. The worst part of it is, they do this over a normal `HTTP` request in plain view of anyone that happens to be sniffing around on the line between them and the server. The same thing applies for user login or registration handling. If the user submits their information via a normal form but `POST`s it to a `HTTP` page, the same kind of information exposure is possible. A simple fix for this one? Use `HTTPS`.

There's also some other "weakness" items that talk about having a poor "lock out" mechanism, poor password policy and bad password reset or security question/answer handling processes. Lets look at these one at a time and talk about the problems that can come up with each and how to effectively test them. First up, we'll look at the "lock out" handling. This is something that I've seen several sites, even major names, forget to add into their process. They want to give the users as many opportunities as possible to access their account and don't lock them out after a certain number of failed attempts. While this may make sense to someone on the business side not wanting to prevent users from logging in and ordering all sorts of goodies, it's terrible from a security aspect. Imagine what this would allow for someone trying to brute force the password on someone's account. If you're not doing any kind of request throttling or locking of the account after a certain number of failures, you're doing it wrong.

Some systems will just lock the user out for a certain amount of time, say fifteen minutes, and then allow them to try their login again. Hopefully the user remembers their credential this time and is able to access the system. If not, they'll have to go through the whole process all over again...unless they reset their password. This brings us to one of the other weaknesses: bad password reset handling. I've already mentioned the problems that can come up with the messaging from password resets, but there's also two major issues that are pretty common and can cause problems. The first issue is the new password being sent in plain-text in an email. There's *lots* if services out there that do this and, unfortunately, it's one of the least secure messaging methods that could be used for something as sensitive as a password. A *much* better option is to send the user an address with a one-time hash appended to it they can click and be able to reset their password from there.

The second all too common issue is that an application, upon the user resetting their password, logs them in immediately. While this may seem like a nice and user-friendly thing to do, you should always force the user to log in with the newly updated password first. This way you can verify they are who they are supposed to be and not have to worry about adding an exception to your authentication process that could potentially be used as a bypass if not protected correctly.

In addition to password reset functionality on the outside, ensure that you're requiring the user to enter their old password right along side the new password if they're changing it themselves. If an attacker somehow found a hole in your authentication system somewhere and was able to access a user's account management system, not having this check would allow them to change the password to whatever they want, all without the user's knowledge. They'd only find out when they came to log in next time (and with "remember me" functionality, an actual login may be a far time off).

The next "weakness" item is something that's always a point of contention among the secure development community: password policies. There's those out there that say that password policies shouldn't exist and it doesn't matter what kind of password the user picks, it's all about the storage of the password. After all, if the storage mechanism is strong enough, you don't have to worry about it being exposed, right? Wrong...well, partly wrong. The storage mechanism *is* important, but so is encouraging users to come up with stronger passwords. This is the whole reason for password policies. If you're storing the passwords the correct way, it won't matter what the actual password string is. It may be stored as a `bcrypt` hash or even an encrypted value, but if a user is allowed to pick the password "12345" you're sunk before you've even left the dock.

Password policies, while annoying (and overly specific at times) are more there to protect the business. People are terrible at coming up with passwords. They use things like their dog's name or their birthday or some other piece of public information that can be easily guessed, compromising the user's account. These policies requiring special characters, at least one number, seven capital letters, etc. help add to the overall complexity of the resulting password hash and make it more difficult for an attacker to crack were they able to get a full dump of the password information. The more *entropy* the password has, the harder it is to guess. Things like special characters, a wider character set and even just adding numbers can increase the time it takes to crack a password by a good bit. Also consider the content of the password - don't let the user include part (or all) of their username or email address in it if at all possible.

A good password policy also includes definitions on the time around required password changes, how often a user can reset their password and how long it is between the time they can use the same password. This last one is a bit more difficult as you have to store the information for the last X number of passwords to compare against. There's more clever ways to do this, but you still have to keep that information handy. As far as the time between resets...even the strongest password policy can't make perfect passwords. If an attacker is able to compromise even one hash in a decent amount of time, they'll be given clues as to how the passwords are stored. However, if a requirement is introduces that makes the user change their password often (even just 90 days can help), the information the attack has been working so hard on may be out of date before he can even get a chance to try it out. Couple this with the "can't use the same password in X amount of times" and you have a pretty strong system that can withstand an attack much better than just a simple system would.

While I'm on the topic of passwords, here's one that's easy to forget, especially if you're using a more "off the shelf" kind of software. With most pre-packaged applications, there's usually something that comes with it to make getting started easier: a default account. With this default account will come default credentials. I've seen some applications that do things a bit better and provide a password for the account. Not a strong one, mind you, but it's a password. Then there are the ones who chose poorly and decided that a default user doesn't really need a password and it's okay to leave it blank. This makes the setup process even easier, right? Well, what happens once someone typically installs and configures their software with this default account? More often than not, it's completely forgotten about. They may create an administrator account for themselves and only log in with that in the future, but that default account is still there, waiting to be used and abused. There's two ways to handle this problem: either remove the account completely (some systems won't allow this) or disable it so it can no longer be accessed. Hopefully this can be done through the user interface, but it may require a little hacking around on your part if not. Oh, and a word of advice to those vendors out there that think "no one should be able to disable the default account" - *you're wrong*.

Finally in the "weakness" area we'll look at the issues with security questions and answers. These "secret" questions are usually made up of overly generic choices, most of which could be found with a quick Google search or two. It's even worse if the user is heavily involved in social media and shares a bit too much about themselves. Think about the questions you've set up in the past...they ask about things like first car, favorite color or even mother's maiden name. These kinds of things can be super simple to find, making the security value of these questions quite a bit less. At this point they're just there to make sure the user *feels* more secure and are not actually more secure. Another issue with these questions is the number of options and the number of times you're allowed to guess at the answers. If there's only three questions to pick from, that significantly reduces the protection level they can provide. The same thing goes for the number of times you can guess at them. Even if you have five different security questions on your account, if you're allowing your users to guess until they get it right, you're adding a lot of risk to the authentication process. Think about hooking this into the "lock out" process I talked about earlier and doing something similar if they guess wrong too many times.



##### Authorization

##### Session Management

##### Input Validation

##### Error Handling

##### Weak Cryptography

##### Logic Failures

##### Client Side




#### Resources

- [The OWASP Testing Project](https://www.owasp.org/index.php/OWASP_Testing_Project)